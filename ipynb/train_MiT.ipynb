{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d699d4f8-ad4a-4c8d-98c3-a73270160f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "from easydict import EasyDict as edict\n",
    "import torch\n",
    "\n",
    "import train_vivq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54dd3d1-ac81-469d-ab5b-d157fcb2b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9699a6e7-38ff-4f50-9585-fec15a465858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching with args:  {'run_name': 'vivq_8192_drop_video', 'model': 'vivq', 'dataset': 'first_stage', 'dataset_path': '/home/projects/DataSets/Moments_in_Time_Raw/tars/{0..333}.tar', 'total_steps': 5000000, 'batch_size': 10, 'num_workers': 10, 'log_period': 100, 'extra_ckpt': 1000, 'accum_grad': 1, 'codebook_size': 8192, 'clip_len': 10, 'skip_frames': 5, 'n_nodes': 1, 'node_id': 0, 'devices': [1]}\n"
     ]
    }
   ],
   "source": [
    "args = edict({})\n",
    "args.run_name      = \"vivq_8192_drop_video\"\n",
    "args.model         = \"vivq\"\n",
    "args.dataset       = \"first_stage\"\n",
    "args.dataset_path  = \"/home/projects/DataSets/Moments_in_Time_Raw/tars/{0..333}.tar\"\n",
    "args.total_steps   = 5_000_000\n",
    "args.batch_size    = 10\n",
    "args.num_workers   = 10\n",
    "args.log_period    = 100\n",
    "args.extra_ckpt    = 1_000\n",
    "args.accum_grad    = 1\n",
    "\n",
    "args.codebook_size = 8192\n",
    "args.clip_len      = 10\n",
    "args.skip_frames   = 5\n",
    "\n",
    "args.n_nodes       = 1\n",
    "args.node_id       = 0\n",
    "args.devices       = [1]\n",
    "\n",
    "print(\"Launching with args: \", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b79e10-b597-447f-9b15-a3ca7467949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 'vivq_8192_drop_video'....\n",
      "Batch Size check: 10\n",
      "Number of Parameters: 43389316\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/lpips/weights/v0.1/vgg.pth\n",
      "Using clip length of 10 and 5 skip frames.\n",
      "\n",
      "\n",
      "-1\n",
      "\n",
      "\n",
      "Loading last checkpoint....\n",
      "Loaded model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized scheduler\n",
      "Sanity check => Last-LR: 0.00025369065938131874 == Current-LR: 0.00025369065938131874 -> True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 419601/5000000 [00:00<?, ?it/s]/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (30 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (25 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (30 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (45 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (46 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (36 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (22 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (46 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (48 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (30 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 128, 128])\n",
      "torch.Size([10, 10, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (33 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (38 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "  8%|▊         | 419602/5000000 [00:33<42834:47:33, 33.67s/it, loss=0.109, d_loss=0.71, lr=0.000254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 128, 128])\n",
      "torch.Size([10, 10, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 419603/5000000 [00:39<22314:53:13, 17.54s/it, loss=0.101, d_loss=0.707, lr=0.000254]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 128, 128])\n",
      "torch.Size([10, 10, 3, 128, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 419604/5000000 [00:40<12419:19:35,  9.76s/it, loss=0.108, d_loss=0.709, lr=0.000254]/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (48 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (25 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n",
      "/root/anaconda3/envs/torch_1.x/lib/python3.10/site-packages/webdataset/handlers.py:33: UserWarning: Exception('Video too short (43 frames), skipping.')\n",
      "  warnings.warn(repr(exn))\n"
     ]
    }
   ],
   "source": [
    "train_vivq.launch(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d45e1-4438-48f1-88ae-5172c5296ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7e580-03f5-4ff0-a05a-638341d9f698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b69b0-12d6-4cf4-95c7-5e63e794ce47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.x",
   "language": "python",
   "name": "torch_1.x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
